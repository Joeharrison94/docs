{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to JH Docs","text":"<p>I started my home labbing journey a few years ago and my enterprise career over a decade ago, so I thought it would be good to document some of my implementations....so here we are!</p>"},{"location":"#check-my-tutorials","title":"Check My Tutorials:","text":"<ul> <li> Google Cloud Platform - Free Forever VM Setup &amp; Configuration Using Terraform </li> <li> Cloudflared Argo Tunnels with Zero Trust! </li> <li> Install KVM (Kernel-Based Virtualization) On Ubuntu Server </li> </ul> Thanks for dropping by \ud83d\udc4d"},{"location":"cloudflared/","title":"Cloudflared Argo Tunnels with Zero Trust","text":"<p>Cloudflare Tunnel requires the installation of a lightweight server-side daemon, cloudflared, to connect your infrastructure to Cloudflare. </p> <p><code>cloudflared</code> is an open source project maintained by Cloudflare.</p> <p>Releases can be found on GitHub. Downloads are available as standalone binaries or packages like Debian and RPM.</p> <p>Detailed release notes can be found on the GitHub RELEASE_NOTES file.</p>"},{"location":"cloudflared/#install-cloudfalred-with-zero-trust-option-1","title":"Install Cloudfalred with Zero Trust (Option 1)","text":"<p>This option will assume you have already setup your domain in Cloudflare and enabled the Zero Trust (formerly Cloudflare Access) panel this will require you to setup at least one method of 2fa, the default is a OTP which is done via email, in my case I have setup Okta as my MFA. </p> <p>In the demo, we will imagine we have a service to run like Sonarr which runs on my  Ubuntu host in docker and exposes port 8989 over HTTP. This is what I will show when setting up the tunnel and application in the below.</p> <p>READ BEFORE PROCEEDING</p> <p><code>REMOVE ALL CNAME AND A RECORDS FROM THE CLOUDFLARE DNS PANEL BEFORE CONTINUING</code></p>"},{"location":"cloudflared/#login-to-the-cloud-flare-zero-trust-panel","title":"Login to the Cloud Flare Zero Trust Panel","text":"<p>The panel can can be found here</p> <p>Once you are logged in you should be greeted with a page that looks like this.</p> <p></p> <p>From this page you will need to select <code>Access</code> in the left hand menu then <code>Tunnels</code> from the sub section. You should then see the button in the top right hand corner which is labeled <code>Create Tunnel</code>.</p> <p></p> <p>Now press the button and follow the process in the below until you are at the point when it asks you to install the <code>Tunnel Connector</code>. Simply name the tunnel and select your source machine os.</p> <p></p> <p>Once you have the screen output of the two code snippets, you will select the one on the left to install, and configure the service, or if you have the <code>cloudflared.service</code> already installed then you will use the snippet on the right. These are bash commands that you run in turn on the same host as your service in this case the same host as our \"Sonarr\" service. When this is installed and configured you can proceed by scrolling down and pressing the next button, then entering the Public Hosname information, finally move back to the overview tab and press the save button.</p> <p></p> <p>With that being done, you should now have access to your application securely over HTTPS on the subdomain you assinged in this case at <code>https://sonarr.j-harrison.co.uk</code>. This will be fine for most applications that you do not want to protect with 2FA, for services like self hosted Plex / Jellyfin instances. However you will have some some other services which you dont want the general public to be able to browse to. This is where the <code>Cloudflare Zero Trust Applications</code> come in very handy.</p> <p></p> <p>This one looks complicated but is very simple. Name the application, then set the <code>Subdomain</code> and <code>Domain</code> to be exactly the same as your <code>Public Hostname</code> setup that we previously configured. Following that you can optionally add a custom logo if you wish but it isn't of much use unless you plan to use the CF dashboard. Name your Policy and assign the group that you created when you signed up, in my case I have it to only allow access from my email address, finally and optionally set the Additional settings (checkboxes) and save!.</p> <p>Now the application is protected and you will be prevented from accessing the site without authenticating with cloudflare first!</p> <p>Tip</p> <p>You can add multiple servers to the tunnel, just add more <code>Public Hostnames</code> in tunnel configuration, then optionally protect them in the <code>Applications</code> section.</p>"},{"location":"cloudflared/#install-cloudflared-manually-option-2","title":"Install Cloudflared Manually (Option 2)","text":"<p>READ BEFORE PROCEEDING</p> <p><code>REMOVE ALL CNAME AND A RECORDS FROM THE CLOUDFLARE DNS PANEL BEFORE CONTINUING</code></p>"},{"location":"cloudflared/#installation-of-cloudflared","title":"Installation of Cloudflared","text":"<p>Log into the machine you wish to add a tunnel to in this example I will be using an Ubuntu Server machine.</p>  bash <pre><code># INSTALL CLOUDFLARED\nmkdir ~/.cloudflared\n\ncd ~/.cloudflared\n\nwget -q https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.deb\n\nsudo dpkg -i cloudflared-stable-linux-amd64.deb\n</code></pre>"},{"location":"cloudflared/#create-the-argo-tunnel","title":"Create The Argo Tunnel","text":"bash <pre><code>#This will create a tunnel json file in ~/.cloudflared named [tunnel-id].json\ncloudflared tunnel create tunnelnamehere \n</code></pre>"},{"location":"cloudflared/#configuration-of-cloudflared","title":"Configuration of Cloudflared","text":"bash <pre><code>cloudflared tunnel login\n</code></pre> <p>This will present you with a link to follow, so open this link in a browser, this doesnt have to be on the same machine this can be done on another device., once complete this will place a <code>cert.pem</code> into <code>~/.cloudflared</code></p>"},{"location":"cloudflared/#create-the-config-file-for-the-argo-tunnel","title":"Create The Config File For The Argo Tunnel","text":"bash <p><pre><code>sudo nano ~/.cloudflared/config.yml\n</code></pre> Place the following inside the newly created file. In this example I am pointing to a reverse proxy that runs on port 443, however you can update the cname and port to be anything you run on the server.</p>  ~/.cloudflared/config.yml <pre><code>tunnel: [TUNNEL-ID TAKEN FROM THE JSON file IT CREATED]\ncredentials-file: /home/USER/.cloudflared/[TUNNEL-ID].json\n\nconfig: /home/USER/.cloudflared/config.yml\n# NOTE: You should only have one ingress tag, so if you uncomment one block comment the others\n\n# forward all traffic to Reverse Proxy w/ SSL\ningress:\n  - hostname: plex.yourdomain.co.uk\n    service: https://0.0.0.0:4444\n    originRequest:\n      connectTimeout: 10s\n      noTLSVerify: true\n  - hostname: docs.yourdomain.co.uk\n    service: https://0.0.0.0:4444\n    originRequest:\n      connectTimeout: 10s\n      noTLSVerify: true\n  - hostname: code.yourdomain.co.uk\n    service: https://0.0.0.0:4444\n    originRequest:\n      connectTimeout: 10s\n      noTLSVerify: true\n  - hostname: ssh.yourdomain.co.uk\n    service: ssh://0.0.0.0:22\n    originRequest:\n      connectTimeout: 10s\n      noTLSVerify: true   \n  - hostname: yourdomain.co.uk\n    service: https://0.0.0.0:4444\n    originRequest:\n      connectTimeout: 10s\n      noTLSVerify: true\n  - service: http_status:404\n</code></pre>"},{"location":"cloudflared/#add-routing-to-your-tunnel-in-cloudflare","title":"Add Routing To Your Tunnel In Cloudflare","text":"<p>The following commands will add CNAME records pointing to your tunnel locations in the Cloudflare DNS Panel.</p>  bash <pre><code>cloudflared tunnel route dns tunnelnamehere  hyperionlabs.co.uk\n\ncloudflared tunnel route dns tunnelnamehere  plex.hyperionlabs.co.uk\n\ncloudflared tunnel route dns tunnelnamehere  docs.hyperionlabs.co.uk\n\ncloudflared tunnel route dns tunnelnamehere  code.hyperionlabs.co.uk\n\ncloudflared tunnel route dns tunnelnamehere  ssh.hyperionlabs.co.uk\n\ncloudflared tunnel route dns tunnelnamehere  www.hyperionlabs.co.uk\n</code></pre>"},{"location":"cloudflared/#setup-the-cloudflared-service","title":"Setup The Cloudflared Service","text":"bash <pre><code>sudo cp ~/.cloudflared/config.yml /etc/cloudflared/config.yml\n\nsudo cloudflared service install\n\nsudo systemctl enable cloudflared\n\nsudo systemctl start cloudflared\n\nsudo systemctl status cloudflared\n\nsudo systemctl start cloudflared-update.timer\n\nsudo systemctl enable cloudflared-update.timer\n\nsudo systemctl status cloudflared-update.timer\n</code></pre> <p>Success</p> <p>This is now complete, but if you ever want to add services be sure to update the <code>config.yml</code> in <code>/etc/cloudflared/</code> and make the tunnel routes for your new services.</p>"},{"location":"gcp-free-forever/","title":"Google Cloud Platform - Deploys an Ubuntu Minimal OS Virtual Machine with Docker-ce and Docker Compose installed using Terraform","text":"<p>My Github Repo For This Project</p> <p>My Github Link - Joeharrison94 / terraform-gcp-ubuntu-container-ready-e2-micro-vm</p> <p>Using the below instructions and supplied files in the repo, you will be able to deploy an e2-micro instance into GCP via  Terraform. This is the free forever tier so it shouldn't cost you a thing.</p> <p>This version comes with  docker &amp; docker compose pre-installed. It will also inject a compose file into the app data drive in <code>/mnt/disks/docker/projects/app</code> my example contains an Uptime Kuma and Healthchecks container.</p> <p>Before you continue make sure that you have your  Gmail account credentials handy as you will need them to setup the Google Cloud account.</p>"},{"location":"gcp-free-forever/#google-cloud-platform-account-registration","title":"Google Cloud Platform Account Registration","text":"<p>Firstly you should understand what exactly you are sigining up for, we are making this account to gain access to the GCP (Google Cloud Platform), in order to make a free forever VPS / VM you can read more on the offerings here.</p> <p> </p> Navigate to https://cloud.google.com and press the \"Get started for free\" button <p> </p> Sign in if prompted. This part is country dependant, you shoud provide your mobile number for SMS verification <p> </p> Fill the form in, ensuring that the \"Account type\" is \"Individual\". Ignore the next few pop-ups that ask you to try products which are billable <p> </p> When you arrive at the home page, select the 'My First Project` dropdown in the upper left. Select 'NEW PROJECT' <p> </p> Name the project this can be anything you want, a project ID will automatically assigned. Click CREATE to finalize youe new project <p> </p> When the green tick appears next to your new project it is ready, click 'SELECT PROJECT' <p> </p> You are taken to the project dashboard, from here select the 'Compute Engine', then enable it on the page it opens. This can take a minute or two to fully enable so please be patient"},{"location":"gcp-free-forever/#google-shell-api-vps-deployment-prep","title":"Google Shell API &amp; VPS Deployment Prep","text":"Now that the Compute Engine is enabled, press the gshell icon in the upper right corner, this will load you into a Google Cloud Shell You will be automatically placed in your users home directory '/home/[USER]'. Copy the commands below to setup the dirs you'll need for the Terraform deployment  bash <pre><code>cd ~/ &amp;&amp; mkdir terraform compose_files .ssh startup auth &amp;&amp; ls\n</code></pre> You should now see all the directories listed here <p>Now it is time to clone my GitHub Repo into the <code>terraform</code> folder.</p>  bash <pre><code>cd terraform &amp;&amp; git clone https://github.com/Joeharrison94/terraform-gcp-ubuntu-container-ready-e2-micro-vm\n</code></pre> <p> </p> This is the output of the clone, following this we need to shuffle some of the files around to different folders. Using the 'Open Editor' in the upper right corner of the shell window <p> </p> I have listed all the files and paths you need to change below to make it easier to read <p>All of the files are currently in the <code>./terraform</code> folder to move them into the correct folder all you need to do is drag and drop them individually.</p> <p>File Locations</p> <ul> <li> <code>docker-compose.yaml</code> <code>./compose_files</code> </li> <li> <code>startup.sh</code> <code>./startup</code> </li> <li> <code>*.tf</code> <code>./terraform</code> </li> </ul>  Folder Structure <pre><code>.                                                                                             \n\u251c\u2500 auth/                               # Folder to store the API user credentials             \n\u251c\u2500 compose_files/                                                                             \n\u2502  \u2514\u2500 docker-compose.yaml              # Docker compose configuration file                    \n\u251c\u2500 startup/                                                                                   \n\u2502  \u2514\u2500 startup.sh                       # Startup script to install dependancies               \n\u2514\u2500 terraform/                                                                                 \n   \u251c\u2500 network-firewall.tf              # Network Firewall Rule Definitions                    \n   \u251c\u2500 network-main.tf                  # Network Definitions                                  \n   \u251c\u2500 network-variables.tf             # Network Terraform Variable Definitions               \n   \u251c\u2500 provider-main.tf                 # GCP Providers Definitions                            \n   \u251c\u2500 provider-variables.tf            # GCP Providers Terraform Variable Definitions         \n   \u251c\u2500 terraform.tfvars                 # Terraform Variable Definitions                       \n   \u251c\u2500 ubnt-versions.tf                 # Ubuntu Version Definitions                           \n   \u251c\u2500 ubnt-vm-main.tf                  # Main VM Configuration Definitions                    \n   \u251c\u2500 ubnt-vm-output.tf                # Information To Display When Provisioning Completes   \n   \u2514\u2500 ubnt-vm-variables.tf             # Main VM Terraform Variable Definitions               \n</code></pre> <p>Now to edit the <code>.tf</code> and <code>.tfvars</code> files inside the <code>./terraform</code> folder. I'm not going to go through them all as they explain what needs altering fairly well, but some pointers:</p> <p>Tip</p> <p><code>IDENTIFIER</code> must be changed in <code>NETWORK-FIREWALL</code> and <code>NETWORK-MAIN</code> files - it doesn't matter what you change it to, but keep it short and the same.</p> <p>The <code>terraform.tfvars</code> requires your <code>project ID</code> , <code>project name</code> , and for you to change the <code>user</code>. This user should be your email address without the @gmail.com, where <code>me@gmail.com</code> becomes <code>me</code>.</p> <p>Caution</p> <p>Do not change the <code>GCP region</code> or <code>zone</code> as the ones selected are in the free forever locations, if you change these you may incur costs.</p> <p> </p> Example modification of `terraform.tfvars`"},{"location":"gcp-free-forever/#api-user-setup","title":"API User Setup","text":"<p>Navigate back to or reopen your Google Cloud Shell terminal.</p> <p>We will now create the SSH keys that you will use to access the VM once it is deployed. Changing the part in [ ] to something else, this is the comment.</p>  bash <pre><code>cd ~/\nssh-keygen -t ed25519 -f ~/.ssh/sshkey -C [KeysForVPSAccess]\n</code></pre> <p>Follow the on-screen instructions and do not set a passphrase, when asked leave it blank and press enter.</p> <p>When this process completes, you will have <code>sshkey</code> and <code>sshkey.pub</code> in your <code>/home/user/.ssh</code> folder.</p> <p> </p> Output of the aforementioned SSH keypair creation process <p>We need to create a service account to use Terraform  with and give it all the required permissions necessary to provision the VM.</p> <p>You may need to authorize the API the first time you run one of the below commands</p>  bash <pre><code># Run all these commands individually and ensure each one completes before moving onto the next one\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##\n## Ensure that you update PROJECT-ID-HERE with your project ID. ##\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##\n\n# Change working directory to the users home folder\ncd ~/\n\n# Creates a service account named tf-serviceaccount \ngcloud iam service-accounts create tf-serviceaccount --description=\"service account for terraform\" --display-name=\"terraform_service_account\"\n\n# List accounts to ensure it was created\ngcloud iam service-accounts list\n\n# Create keys for the service account to use when provisioning and store them in the auth folder.\ngcloud iam service-accounts keys create ~/auth/google-key.json --iam-account tf-serviceaccount@PROJECT-ID-HERE.iam.gserviceaccount.com\n</code></pre> <p>With this done we will now add the following permissions to the service account.</p>  bash <pre><code># Run all these commands individually and ensure each one completes before moving onto the next one\n\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##\n## Ensure that you update PROJECT-ID-HERE with your project ID. ##\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##\n\ngcloud services enable cloudresourcemanager.googleapis.com\n\ngcloud services enable cloudbilling.googleapis.com\n\ngcloud services enable iam.googleapis.com\n\ngcloud services enable storage.googleapis.com\n\ngcloud services enable serviceusage.googleapis.com\n\ngcloud projects add-iam-policy-binding PROJECT-ID-HERE --member serviceAccount:tf-serviceaccount@PROJECT-ID-HERE.iam.gserviceaccount.com --role roles/viewer\n\ngcloud projects add-iam-policy-binding PROJECT-ID-HERE --member serviceAccount:tf-serviceaccount@PROJECT-ID-HERE.iam.gserviceaccount.com --role roles/storage.admin\n\ngcloud projects add-iam-policy-binding PROJECT-ID-HERE --member serviceAccount:tf-serviceaccount@PROJECT-ID-HERE.iam.gserviceaccount.com --role roles/compute.instanceAdmin.v1\n\ngcloud projects add-iam-policy-binding PROJECT-ID-HERE --member serviceAccount:tf-serviceaccount@PROJECT-ID-HERE.iam.gserviceaccount.com --role roles/compute.networkAdmin\n\ngcloud projects add-iam-policy-binding PROJECT-ID-HERE --member serviceAccount:tf-serviceaccount@PROJECT-ID-HERE.iam.gserviceaccount.com --role roles/compute.securityAdmin\n</code></pre>"},{"location":"gcp-free-forever/#vps-vm-deployment","title":"VPS / VM Deployment","text":"<p>Now that we have created the service account you can now use Terraform  to create the VM.</p>  bash <pre><code>cd ~/terraform\nterraform init\n</code></pre> <p> </p> Terraform Initialization <p>If the init returns with no errors, then we can move onto the <code>plan</code> stage.</p>  bash <pre><code>terraform plan\n</code></pre> <p>When prompted type a name for your VM, type in anything you want but keep it simple.</p> <p>If the plan returns with no errors, we can move onto the final stage where it will apply the config. When you proceed ensure that you type in the same VM name that you entered in the plan stage. Finally when prompted type 'yes' then hit enter to deploy your VM.</p>  bash <pre><code>terraform apply\n</code></pre> <p> </p> Terraform Applying <p>The full deployment and configuration will take some time to complete fully, but if everything was configured according to this guide, your screen should show that 7 resources have been added without fault.</p> <p>Head back to your <code>Compute Engine</code>, and check out <code>VM Instances</code>, your VM will be ready and waiting.</p> <p> </p> Behold Your VM <p>Caution</p> <p>An important thing to note, is that as part of the <code>startup.sh</code> script it will install and configure docker &amp; docker compose and inject the compose file. </p> <p>Because of this I would give the VM time to complete all the actions it needs to before you login, 5-10 minutes should be ample time.</p> <p>Now click the <code>SSH</code> button this will prompt a browser window, and after injecting the SSH keys (takes a while, so don't worry), it will successfully connect to the VM.</p> <p> </p> Accessing The VM <p>Quick Note</p> <p>You can use the private key <code>~/.ssh/sshkey</code> to SSH into the machine using the public IP remotely, you can see the IP displayed in your Terraform outputs.</p>"},{"location":"gcp-free-forever/#docker-containers-uptime-kuma-healthschecks","title":"Docker Containers - Uptime Kuma &amp; Healthschecks!","text":"<p>Navigate to the directory <code>/mnt/disks/docker/projects/app</code> <code>ls</code> the directory to find the injected <code>docker-compose.yaml</code> </p>  bash <pre><code>cd /mnt/disks/docker/projects/app\nls\n</code></pre> My docker-compose.yaml file is missing? Click Here <p>If for some reason the docker-compose.yaml hasn't been injected after 15 minutes of VM uptime for whatever reason.  Create it with the below commands.</p>  bash <pre><code>cd /mnt/disks/docker/projects/app\n\nsudo touch docker-compose.yaml\n\n# After the below command runs it will open the empy file, copy in the contents of the file from my GitHub repo, save it then exit with 'CTRL + S' then 'CTRL + X'\nsudo nano docker-compose.yaml \n</code></pre> <p>Navigate to the docker folder, then create the folders below and spin up the docker containers.</p>  bash <pre><code>cd /mnt/disks/docker\n\nsudo mkdir uptime-kuma healthchecks\n\n# Option 1\nsudo docker compose -f /mnt/disks/docker/projects/app/docker-compose.yaml up -d\n\n# Option 2\n# You can either add your user to the 'docker' user group so you dont have to use sudo to run docker commands, or just use sudo\nsudo usermod -aG docker $USER\ndocker compose -f /mnt/disks/docker/projects/app/docker-compose.yaml up -d\n</code></pre> <p>Check that your containers up and running.</p>  bash <pre><code>sudo docker ps # Or just 'docker ps' if you added your user to the 'docker' user group\n</code></pre> <p> </p> Checking The Docker Containers <p>Your containers are now running and functional!</p>"},{"location":"gcp-free-forever/#setting-the-public-firewall","title":"Setting The Public Firewall","text":"<p>But now you need to access them, access for now will be via the public IP and the port. Right now it will not work as you have now rules to allow it.</p> <p>Take note of the uptime-kuma port (3001). </p> <p>Head over to the VM page (we no longer require te cloud terminal, close it if you so wish).</p> <p> </p> Opening The Firewall <p>Click the button <code>Set up firewall rules</code> then <code>CREATE FIREWALL RULE</code> at the top of the page. Follow the onscreen prompts adding a rule name, network information and port.</p> <p> </p> Setting The Firewall <p>Take note of the external IP of your VM in the <code>VM instances</code> screen, in a new browser tab navigate to http://EXTERNALIP:3001</p> <p>This will take you to your Uptime Kuma service!</p> <p> </p> First Time Setup Screen - Uptime Kuma <p>Final Note</p> <p>By Default Google sets the VM networking to premium, so dont forget to go and change it to standard, as shown here.</p> <p></p> <p>Congratulations! You've got access to your Uptime-Kuma instance!, you can also follow the same steps with regards to the Healthchecks container.</p> <p>Success</p> <p>CONGRATULATIONS! You have successfully deployed a Google Cloud Platform VM with functional docker containers using Terraform!</p> <p>However this method of access is not secure at all as anyone can access you service if they have the IP and port of your VM not to mention it is plain text HTTP a BIG no no. We need HTTPS This is where Cloudflare and their awesome suite of security tools save the day. I have a seperate guide that runs through all of this which I will link to in the section below.</p> <p>Thanks for reading and happy home labbing!</p>"},{"location":"gcp-free-forever/#setting-up-a-cloudflared-argo-tunnel-with-zero-trust","title":"Setting Up A Cloudflared Argo Tunnel With Zero Trust!","text":"<p>Cloudflared Argo Tunnels with Zero Trust!</p>"},{"location":"gcp-free-forever/#links","title":"Links","text":"<p>An honourable mention to  <code>u/BackedUpBooty</code> for supplying me with all the screenshots I used for this guide and for the lovely writeup he gave me that inspired me to improve my doc's for this project Link to the blog post here!.</p>"},{"location":"kvm-ubuntu/","title":"Kernel-Based Virtualization - Deploys Virtual Machines on Ubuntu Server OS","text":""},{"location":"kvm-ubuntu/#prerequisites","title":"Prerequisites","text":"<p>Before you continue you must have enabled CPU virtualization in the bios, this will vary from manufacturer to manufacturer so ensure that you check your motherboard manual for the correct setting. Here is a link to a handy guide to get you started with this.</p>"},{"location":"kvm-ubuntu/#install-dependancies","title":"Install Dependancies","text":"<p>Install Kvm and all required dependencies to setup a virtualization environment on your  Ubuntu 20.04 LTS sever using command:</p>  bash <p>Info</p> <p>Here is what you are installing.</p> <p><code>qemu</code> - A generic machine emulator and virtualizer.</p> <p><code>qemu-kvm</code> - QEMU metapackage for KVM support (i.e. QEMU Full virtualization on x86 hardware).</p> <p><code>libvirt-clients</code> - programs for the libvirt library.</p> <p><code>libvirt-daemon-system</code> - Libvirt daemon configuration files.</p> <p><code>virtinst</code> - programs to create and clone virtual machines.</p> <p><code>bridge-utils</code> - utilities for configuring the Linux Ethernet bridge.</p> <pre><code>sudo apt install qemu qemu-kvm libvirt-clients libvirt-daemon-system virtinst bridge-utils\n</code></pre> <p>With the above packages installed, before you can continue you must check your hosts virtualisation capabilities, execute the following command to make sure your processor supports virtualisation capabilities and it has been enabled properly in the BIOS:</p>  bash <pre><code>kvm-ok\n</code></pre> <p>Sample Output     <pre><code>INFO: /dev/kvm exists\nKVM acceleration can be used\n</code></pre></p> <p>If you do not get the above output, you need to check the BIOS settings mentioned in the prerequisites section</p> <p>Once KVM is installed and you have verified that KVM is happy with the virtualization capabilites, start the <code>libvertd</code> service (If it is not started already):</p>  bash <pre><code>sudo systemctl enable libvirtd\nsudo systemctl start libvirtd\n</code></pre> <p>Check the status of libvirtd service with command:</p>  bash <p><pre><code>systemctl status libvirtd\n</code></pre> Sample output:</p> <pre><code> \u25cf libvirtd.service - Virtualization daemon    \n     Loaded: loaded (/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled)\n     Active: active (running) since Sat 2020-07-04 08:13:41 UTC; 7min ago\nTriggeredBy: \u25cf libvirtd-ro.socket\n             \u25cf libvirtd-admin.socket\n             \u25cf libvirtd.socket\n       Docs: man:libvirtd(8)\n             https://libvirt.org\n   Main PID: 4492 (libvirtd)\n      Tasks: 19 (limit: 32768)\n     Memory: 12.9M\n     CGroup: /system.slice/libvirtd.service\n             \u251c\u25004492 /usr/sbin/libvirtd\n             \u251c\u25004641 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --l&gt;\n             \u2514\u25004642 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --l&gt;\n\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: compile time options: IPv6 GNU-getopt DBus i18n&gt;\n Jul 04 08:13:42 ubuntuserver dnsmasq-dhcp[4641]: DHCP, IP range 192.168.122.2 -- 192.168.12&gt;\n Jul 04 08:13:42 ubuntuserver dnsmasq-dhcp[4641]: DHCP, sockets bound exclusively to interfa&gt;\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: reading /etc/resolv.conf\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: using nameserver 127.0.0.53#53\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: read /etc/hosts - 7 addresses\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: read /var/lib/libvirt/dnsmasq/default.addnhosts&gt;\n Jul 04 08:13:42 ubuntuserver dnsmasq-dhcp[4641]: read /var/lib/libvirt/dnsmasq/default.host&gt;\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: reading /etc/resolv.conf\n Jul 04 08:13:42 ubuntuserver dnsmasq[4641]: using nameserver 127.0.0.53#53\n</code></pre> <p>The <code>libvertd</code> service has been enabled and started! Let us continue witht the networking now.</p>"},{"location":"kvm-ubuntu/#networking","title":"Networking","text":"<p>We shall be using bridged networking with KVM. A bridged network shares the real network interface of the host computer with other VMs to connect to the outside network. Therefore each VM can bind directly to any available IPv4 or IPv6 addresses, just like a physical computer would do.</p> <p>By default KVM setups a private virtual bridge, so that all VMs can communicate with each another, within the host computer internally. It provides its own subnet and DHCP to configure the guest\u2019s network and uses NAT to access the host network.</p> <p>The KVM default network <code>virbr0</code> uses <code>192.168.122.1/24</code> IP address. All the VMs will use an IP address in the <code>192.168.122.0/24</code> IP range and the host OS will be reachable at <code>192.168.122.1</code>. You should be able to ssh into the host OS (at <code>192.168.122.1</code>) from inside the guest OS and use scp to copy files back and forth.</p> <p>It is OK if you only access the VMs inside from the host itself. However we can't access the VMs from other remote systems in the hosts attached network.</p> <p>Because they use different IP range i.e. <code>10.0.180.0/24</code> in my case. In order to access the VMs from other remote hosts, we must setup a public bridge that runs on the host network and uses whatever external DHCP server is on the host network.</p> <p>To put this in layman terms, we are going to make all VMs to use the same subnet used by the host system.</p> <p>Before setting up a public bridged network, we should disable Netfilter for performance and security reasons. Netfilter is currently enabled on bridges by default.</p> <p>To disable netfilter, create a file called <code>/etc/sysctl.d/bridge.conf</code></p>  bash <pre><code>sudo nano /etc/sysctl.d/bridge.conf\n</code></pre> <p>Add the following lines:</p>  bash <pre><code>net.bridge.bridge-nf-call-ip6tables=0\nnet.bridge.bridge-nf-call-iptables=0\nnet.bridge.bridge-nf-call-arptables=0\n</code></pre> <p>Save and close the file.</p> <p>Then create another file called <code>/etc/udev/rules.d/99-bridge.rules</code></p>  bash <pre><code>sudo nano /etc/udev/rules.d/99-bridge.rules\n</code></pre> <p>Add the following line:</p>  bash <pre><code>ACTION==\"add\", SUBSYSTEM==\"module\", KERNEL==\"br_netfilter\", RUN+=\"/sbin/sysctl -p /etc/sysctl.d/bridge.conf\"\n</code></pre> <p>This will set the necessary flags to disable netfilter on bridges at the appropriate place in system start-up. Save and close the file. </p> <p>Reboot your system to take effect these changes.</p> <p>Next, we should disable the default networking that KVM installed for itself.</p> <p>Find the name of KVM default network interfaces using \"ip link\" command:</p>  bash <pre><code>ip link\n</code></pre> <p>Sample output:</p>  bash <pre><code>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 08:00:27:8a:52:94 brd ff:ff:ff:ff:ff:ff\n3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 08:00:27:10:7c:c1 brd ff:ff:ff:ff:ff:ff\n4: enp0s9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 08:00:27:5d:61:28 brd ff:ff:ff:ff:ff:ff\n5: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default qlen 100    0\n    link/ether 52:54:00:1f:a2:e7 brd ff:ff:ff:ff:ff:ff\n6: virbr0-nic: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc fq_codel master virbr0 state DOWN mode DEFAULT group default qlen 1000\n    link/ether 52:54:00:1f:a2:e7 brd ff:ff:ff:ff:ff:ff\n</code></pre> <p>As you see in the above output, the entries <code>virbr0</code> and <code>virbr0-nic</code> are the KVM networks.</p> <p>Let us remove the default KVM network with command:</p>  bash <pre><code>virsh net-destroy default\n</code></pre> <p>Sample output:</p>  bash <pre><code>Network default destroyed\nUndefine the default network with command: virsh net-undefine default\n</code></pre> <p>Now run the command it displayed above</p>  bash <pre><code>virsh net-undefine default\n</code></pre> <p>Sample output:</p>  bash <pre><code>Network default has been undefined\n</code></pre> Tip <p>If the above commands didn't work for any reason, you can use these commands to disable and undefine KVM default network.</p>  bash <pre><code>sudo ip link delete virbr0 type bridge\nsudo ip link delete virbr0-nic\n</code></pre> <p>Now run <code>ip link</code> again to verify if the virbr0 and virbr0-nic interfaces are actually deleted.</p> <p>$ ip link=== \" bash\"     <pre><code>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 08:00:27:8a:52:94 brd ff:ff:ff:ff:ff:ff\n3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 08:00:27:10:7c:c1 brd ff:ff:ff:ff:ff:ff\n4: enp0s9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 08:00:27:5d:61:28 brd ff:ff:ff:ff:ff:ff\n</code></pre></p> <p>See? Now the KVM default networks are gone.</p> <p>Now, let us setup the KVM public bridge to use when creating a new VM.</p> <p>Note</p> <p>Do not use wireless network interface cards for bridges. Most wireless interlaces do not support bridging. Always use wired network interfaces for seamless connectivity!</p> <p>To create a network bridge in host, edit <code>/etc/netplan/00-installer-config.yaml</code> file and add the bridge details.</p> <p>Here is the default contents of the <code>00-installer-config.yaml</code> file in my Ubuntu 20.04 LTS server.</p>  bash <p><pre><code>cat /etc/netplan/00-installer-config.yaml\n</code></pre> <pre><code># This is the network config written by 'subiquity'\nnetwork:\n  ethernets:\n    enp3s0:\n      dhcp4: false\n      addresses:\n      - 10.0.180.4/24\n      gateway4: 10.0.180.1\n      nameservers:\n        addresses:\n        - 10.0.180.1\n        - 172.64.36.1\n        search: []\n  version: 2\n  renderer: NetworkManager\n</code></pre></p> <p>As you see, I have a wired network interface namely enp3s0 in my Ubuntu server.</p> <p>Tip</p> <p>Before editing this file, backup your existing <code>/etc/netplan/00-installer-config.yaml</code> file.</p>  bash <pre><code>sudo cp /etc/netplan/00-installer-config.yaml{,.backup}\n</code></pre> <p>Then edit the default config file using your favorite editor, for me this is nano.</p>  bash <pre><code>sudo nano /etc/netplan/00-installer-config.yaml\n</code></pre> <p>Add/modify it like below you should also note that the subnet for you will likely differ from mine so replace the below values that matches with your network:</p>  bash <pre><code># This is the network config written by 'subiquity'\nnetwork:\n  ethernets:\n    enp3s0:\n      dhcp4: false\n  bridges:\n    br0:\n      interfaces: [ enp3s0 ]\n      addresses: [10.0.180.4/24]\n      gateway4: 10.0.180.1\n      mtu: 1500\n      nameservers:\n        addresses: [10.0.180.1,1.1.1.1]\n      parameters:\n        stp: true\n        forward-delay: 4\n      dhcp4: no\n      dhcp6: no\n  version: 2\n  renderer: NetworkManager\n</code></pre> <p>Here, the bridge network interface <code>br0</code> is attached to host's network interface <code>enp0s3</code>. The ip address of <code>br0</code> is <code>10.0.180.4</code>. The gateway is <code>10.0.180.1</code>. I use Cloudflare DNS servers (<code>1.1.1.1</code> and <code>1.0.0.1</code>) to connect to Internet.</p> <p>Make sure the space indentation are exactly same as above. If the line indentations are not correct, the bridged network interface will not activate. </p> <p>Warning!</p> <p><code>Again to reiterate replace the above values that matches with your network</code>.</p> <p>After modifying the network config file, save and close it. Apply the changes by running the following command:</p>  bash <pre><code>sudo netplan --debug  apply\n</code></pre> <p>You can also use the <code>brctl</code> command to show the bridge status:</p> <p>Sample output:</p>  bash <pre><code>brctl show br0\n\nbridge name    bridge id            STP    enabled interfaces\nbr0            8000.0800278a5294    yes    enp0s3\n</code></pre> <p>Now we should configure KVM to use this bridge. To do that, create a an XML file called <code>host-bridge.xml</code>.</p> <p>It doesn't really matter where you create this file but I made it in <code>~/</code> (which is <code>/home/username/</code>).</p>  bash <pre><code>nano host-bridge.xml\n</code></pre> <p>Add the following lines:</p>  xml <pre><code>&lt;network&gt;\n  &lt;name&gt;host-bridge&lt;/name&gt;\n  &lt;forward mode=\"bridge\"/&gt;\n  &lt;bridge name=\"br0\"/&gt;\n&lt;/network&gt;\n</code></pre> <p>Run the following commands to start the newly created bridge and make it as default bridge for all VMs.</p>  bash <pre><code>virsh net-define host-bridge.xml\nvirsh net-start host-bridge\nvirsh net-autostart host-bridge\n</code></pre> <p>To verify if the bridge is active and started, run:</p>  bash <pre><code>virsh net-list --all\n</code></pre> <p>Sample output:</p>  bash <pre><code>Name          State    Autostart   Persistent\n------------------------------------------------\nhost-bridge   active   yes         yes\n</code></pre> <p>Congratulations! You have successfully setup KVM bridge and it is active now.</p>"},{"location":"kvm-ubuntu/#installing-a-vm","title":"Installing a VM","text":"<p>To install a VM you will need to have an ISO on hand for the installation process, as well as for an easy way to access a console session to install the virtual machine you should try cockpit. Cockpit is an amazing open source tool that comes included in Ubuntu <code>17.04</code> and later. To activate cockpit you should run the below commands, included in these are the additional addons for virtual machine management and package updates etc.</p>  bash <pre><code>sudo apt install cockpit cockpit-machines cockpit-packagekit -y\nsudo systemctl enable cockpit\nsudo systemctl start cockpit\n</code></pre> <p><code>cockpit</code> will no be accessible on <code>ip-address-of-machine:9090</code> via a webbrowser.</p> <p>Now once you have installed cockpit you are ready to deploy your first virtual machine!</p>  bash <p>Important Information</p> <p>For the command <code>virt-install</code> there are a lot of arguments that we will be adding, here is a brief explanation of these arguments, ensure you change the values to suit your needs.</p> <p><code>--name</code> - Is the name of the virtual machine you wish to create.</p> <p><code>--ram</code> - Is the amount of RAM in MB's that you want to allocate to the VM.</p> <p><code>--vcpus</code> - Is the amount of CPU threads that you want to allocate to the VM.</p> <p><code>--cpu</code> - Expose the host CPUs configuration to the guest. This enables the guest to take advantage of many of the host CPUs features (better performance), but may cause issues if migrating the guest to a host without an identical CPU.</p> <p><code>--hvm</code> - Requests the use of full virtualization, if both para &amp; full virtualization are available on the host. This parameter may not be available if connecting to a Xen hypervisor on a machine without hardware virtualization support. This parameter is implied if connecting to a <code>QEMU</code> based hypervisor.</p> <p><code>--disk path=</code> - Is the path to the location in which you wish to stor the VM's hard disk.</p> <p><code>,size</code> - Is the size of the VM's hard disk in GB's.</p> <p><code>--cdrom</code> - Is the path to the ISO file you wish to install the VM OS from.</p> <p><code>--network</code> - Is the network that you wan to put the VM on, in our case the bridge network we created earlier.</p> <p><code>--graphics</code> - Specifies the graphical display configuration. This does not configure any virtual hardware, just how the guest's graphical display can be accessed.</p> <p><code>--autorestart</code> -  Set the <code>autostart</code> flag for the VM. This causes the VM to be started on host boot up / reboot.</p> <pre><code>sudo virt-install --name VM-NAME-HERE --ram=4096 --vcpus=4 --cpu host --hvm --disk path=/var/lib/libvirt/images/VM-NAME-HERE,size=50 --cdrom /path/to/iso/vm-os.iso --network bridge=br0 --graphics vnc --autostart\n</code></pre> <p>This will now execute and install your VM, the above command in my case was used to install a <code>Windows 10</code> VM, which needs user input to install unless you made youe own auto install image. So to setup the VM myself, I use the aforementioned application <code>cockpit</code>.</p> <p>Now head over to Cockpit (<code>http://host-ip-address:9090</code>) login with your user, from the main page you will notice a tab for <code>Virtual Machines</code> and from there drop down the menu of your VM. You will see a <code>Consoles</code> tab. Select this and you should see the output of the VM's console, allowing you to view and setup the VM. Once this is done you can (for Windows) setup remote access via RDP, SSH or otherwise.</p> <p>CONGRATULATIONS! Enjoy your new KVM hypervisor.</p>"},{"location":"mkdocs-cheatsheet/","title":"Markdown Cheatsheet For MkDocs","text":""},{"location":"mkdocs-cheatsheet/#collapsible-blocks","title":"Collapsible blocks","text":"<p>This is just a collection of most of the things I use in MkDocs, feel free to use this as a quick reference, rather than sifting through all the official docs.</p> <p>When the markdown extension pymdownx.details is enabled and an admonition block is started with <code>???</code> instead of <code>!!!</code>, the admonition is rendered as a collapsible block with a small toggle on the right side:</p> Admonition, collapsible<pre><code>??? note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Adding a <code>+</code> after the <code>???</code> token renders the block expanded:</p> Admonition, collapsible and initially expanded<pre><code>???+ note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"mkdocs-cheatsheet/#supported-types","title":"Supported types","text":"<p>Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is <code>note</code>:</p>  Markdown Title <pre><code>!!! info \":fontawesome-brands-markdown: Markdown Title\"\n    Info here\n</code></pre> <p><code>note</code></p> <p>Note</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>abstract</code>, <code>summary</code>, <code>tldr</code></p> <p>Abstract</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>info</code>, <code>todo</code></p> <p>Info</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>tip</code>, <code>hint</code>, <code>important</code></p> <p>Tip</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>success</code>, <code>check</code>, <code>done</code></p> <p>Success</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>question</code>, <code>help</code>, <code>faq</code></p> <p>Question</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>warning</code>, <code>caution</code>, <code>attention</code></p> <p>Warning</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>failure</code>, <code>fail</code>, <code>missing</code></p> <p>Failure</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>danger</code>, <code>error</code></p> <p>Danger</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>bug</code></p> <p>Bug</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>example</code></p> <p>Example</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p><code>quote</code>, <code>cite</code></p> <p>Quote</p> <pre><code>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\neuismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\npurus auctor massa, nec semper lorem quam in massa.\n</code></pre>"},{"location":"mkdocs-cheatsheet/#icons","title":"Icons","text":"<p><code>:fontawesome-brands-cloudflare:</code>= </p> <p><code>:fontawesome-brands-ubuntu:</code> = </p> <p><code>:fontawesome-brands-markdown:</code> = </p> <p><code>:fontawesome-brands-github:</code> = </p> <p><code>:fontawesome-brands-reddit:</code> = </p> <p><code>:fontawesome-brands-linux:</code> = </p> <p><code>:fontawesome-brands-js:</code> = </p> <p><code>:fontawesome-brands-html5:</code> = </p> <p><code>:fontawesome-brands-css3:</code> = </p> <p><code>:fontawesome-brands-chrome:</code> = </p> <p><code>:fontawesome-brands-edge:</code> = </p> <p><code>:material-bash:</code> = </p> <p><code>:material-clock-fast:</code> = </p> <p><code>:material-google-cloud:</code> = </p> <p><code>:material-terraform:</code> = </p> <p><code>:fontawesome-brands-reddit-alien:</code> = </p>"},{"location":"mkdocs-cheatsheet/#tables","title":"Tables","text":"Enabled Disabled <p><code>=== \":octicons-check-circle-fill-16: Enabled\"</code></p> <p><code>=== \":octicons-skip-16: Disabled\"</code></p>"}]}